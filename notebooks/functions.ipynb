{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34cdae72-476b-4102-ab1c-f39b41a8a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_SIZES = [\n",
    "    \"spark-worker-m\",\n",
    "    \"spark-worker-l\"\n",
    "]\n",
    "\n",
    "DATABIO_SIZES = {\n",
    "  \"databio-s-1-2\":         54_343,\n",
    "  \"databio-s-2-7\":        274_266,\n",
    "  \"databio-s-1-0\":        321_138,\n",
    "  \"databio-m-7-0\":      2_764_185,\n",
    "  \"databio-m-7-3\":      4_410_928,\n",
    "  \"databio-l-0-8\":    164_214_743,\n",
    "  \"databio-l-4-8\":    227_869_400,\n",
    "  \"databio-l-7-8\":    307_298_107,\n",
    "  \"databio-xl-3-0\": 1_087_646_273\n",
    "}\n",
    "\n",
    "RESULTS_PATH_PREFIX = \"../results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06e56193-ee5d-47b1-a7dd-ba5e567f13c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_benchmarks_interval_join(directories: list[str]):\n",
    "    datasets = []\n",
    "\n",
    "    for directory in directories:\n",
    "        for cluster_size in CLUSTER_SIZES:\n",
    "            data_files_path = \"/\".join([RESULTS_PATH_PREFIX, cluster_size, directory])\n",
    "            print(f\"Loading benchmark results from {data_files_path}.\")\n",
    "            \n",
    "            data_files = [file for file in os.listdir(data_files_path) if file.endswith('.csv')]\n",
    "            dataset = pd.concat(map(lambda data_file: pd.read_csv(f\"{data_files_path}/{data_file}\", on_bad_lines=\"warn\"), data_files))\n",
    "            dataset = dataset.query('result == \"success\"')\n",
    "        \n",
    "            for column_name in [\"elapsed_time\"]:\n",
    "                dataset[column_name] = pd.to_numeric(dataset[column_name], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "            dataset[\"_directory\"] = directory\n",
    "            dataset[\"data_suite_type\"] = dataset.apply(lambda row: \"databio\" if row[\"data_suite\"].startswith(\"databio\") else \"synthetic\", axis=1)\n",
    "            dataset[\"data_suite_name\"] = dataset.apply(lambda row: row[\"data_suite\"] if row[\"data_suite_type\"] == \"databio\" else row[\"data_suite\"][:row[\"data_suite\"].rfind('-')], axis=1)\n",
    "            dataset[\"data_suite_name_short\"] = dataset.apply(lambda row: row[\"data_suite\"].replace(\"databio-\", \"\") if row[\"data_suite_type\"] == \"databio\" else row[\"data_suite_name\"], axis=1)\n",
    "            dataset[\"data_suite_size\"] = dataset.apply(lambda row: DATABIO_SIZES[row[\"data_suite_name\"]] if row[\"data_suite_type\"] == \"databio\" else row[\"data_suite\"][row[\"data_suite\"].rfind('-') + 1:], axis=1)\n",
    "            dataset[\"data_suite_size\"] = pd.to_numeric(dataset[\"data_suite_size\"], errors='coerce').astype(int)        \n",
    "            dataset[\"elapsed_time_s\"] = dataset[\"elapsed_time\"] // 1000\n",
    "            dataset[\"cluster_size\"] = cluster_size\n",
    "    \n",
    "            datasets.append(dataset)\n",
    "\n",
    "    return datasets    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1337889e-63ba-40d1-a247-4dbb4b08b6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_joins_synthetic_benchmark(join_names = None, directories = [\"interval-join\"]):\n",
    "    datasets = load_benchmarks_interval_join(directories)\n",
    "\n",
    "    synthetic_data = pd.concat(datasets)\n",
    "    synthetic_data = synthetic_data.query(f\"data_suite_type == 'synthetic'\")\n",
    "\n",
    "    if join_names is None:\n",
    "        join_names = synthetic_data[\"join_name\"].unique()\n",
    "        join_names = list(join_names)\n",
    "        join_names.sort()\n",
    "    else:\n",
    "        synthetic_data = synthetic_data[synthetic_data[\"join_name\"].isin(join_names)]\n",
    "\n",
    "\n",
    "    data_sizes = synthetic_data[\"data_suite_size\"].unique()\n",
    "    data_sizes = list(data_sizes)\n",
    "    data_sizes.sort()\n",
    "\n",
    "    data_suites = synthetic_data[\"data_suite_name\"].unique()\n",
    "    data_suites = list(data_suites)\n",
    "    data_suites.sort()\n",
    "\n",
    "    plot_figure, plot_axes = plt.subplots(len(data_suites), len(CLUSTER_SIZES), figsize=(16, 4 * len(data_suites)), sharex = True, sharey = \"all\")\n",
    "    plt.ticklabel_format(useOffset=False)\n",
    "    shared_ax = None\n",
    "\n",
    "    for (j, cluster_size) in enumerate(CLUSTER_SIZES):\n",
    "        plot_data = synthetic_data\n",
    "        plot_data = plot_data.query(f\"cluster_size == '{cluster_size}'\")\n",
    "        \n",
    "        for (i, data_suite_name) in enumerate(data_suites):\n",
    "            subplot_data = plot_data.query(f\"data_suite_name == '{data_suite_name}'\")\n",
    "    \n",
    "            sns.barplot(x=\"data_suite_size\", y=\"elapsed_time_s\", hue=\"join_name\", data=subplot_data, ax=plot_axes[i, j])\n",
    "            # plot_axes[i, j].set_xticklabels(plot_axes[i, j].get_xticks(), rotation=45)\n",
    "            plot_axes[i, j].legend()\n",
    "            plot_axes[i, j].set_title(f\"Cluster: {cluster_size}, dataset: {data_suite_name}.\")\n",
    "            \n",
    "            plot_axes[i, j].xaxis.set_tick_params(labelbottom=True)\n",
    "            plot_axes[i, j].yaxis.set_tick_params(labelbottom=True)\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9e3aa45-3f52-4e94-9417-bd588e443a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_joins_databio_benchmark(join_names = None, directories = [\"interval-join\"]):\n",
    "    datasets = load_benchmarks_interval_join(directories)\n",
    "\n",
    "    synthetic_data = pd.concat(datasets)\n",
    "    synthetic_data = synthetic_data.query(f\"data_suite_type == 'databio'\")\n",
    "\n",
    "    if join_names is None:\n",
    "        join_names = synthetic_data[\"join_name\"].unique()\n",
    "        join_names = list(join_names)\n",
    "        join_names.sort()\n",
    "    else:\n",
    "        synthetic_data = synthetic_data[synthetic_data[\"join_name\"].isin(join_names)]\n",
    "\n",
    "\n",
    "    data_sizes = synthetic_data[\"data_suite_size\"].unique()\n",
    "    data_sizes = list(data_sizes)\n",
    "    data_sizes.sort()\n",
    "\n",
    "    data_suites = synthetic_data[\"data_suite_name\"].unique()\n",
    "    data_suites = list(data_suites)\n",
    "    data_suites.sort()\n",
    "\n",
    "    plot_figure, plot_axes = plt.subplots(1, len(CLUSTER_SIZES), figsize=(16, 4), sharex = True, sharey = \"all\")\n",
    "    plt.ticklabel_format(useOffset=False)\n",
    "    shared_ax = None\n",
    "\n",
    "    for (j, cluster_size) in enumerate(CLUSTER_SIZES):\n",
    "        plot_data = synthetic_data\n",
    "        plot_data = plot_data.query(f\"cluster_size == '{cluster_size}'\")\n",
    "        \n",
    "        sns.barplot(x=\"data_suite_name_short\", y=\"elapsed_time_s\", hue=\"join_name\", data=plot_data, ax=plot_axes[j])\n",
    "        # plot_axes[i, j].set_xticklabels(plot_axes[i, j].get_xticks(), rotation=45)\n",
    "        plot_axes[j].legend()\n",
    "        plot_axes[j].set_title(f\"Cluster: {cluster_size}.\")\n",
    "        \n",
    "        plot_axes[j].xaxis.set_tick_params(labelbottom=True)\n",
    "        plot_axes[j].yaxis.set_tick_params(labelbottom=True)\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e4ec9b5-9b09-4d27-98a0-2f0ef901b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_benchmarks_preprocessing():\n",
    "    datasets = []\n",
    "\n",
    "    for cluster_size in CLUSTER_SIZES:\n",
    "        data_files_path = \"/\".join([RESULTS_PATH_PREFIX, cluster_size, \"preprocessing\"])\n",
    "        print(f\"Loading benchmark results from {data_files_path}.\")\n",
    "        \n",
    "        data_files = [file for file in os.listdir(data_files_path) if file.endswith('.csv')]\n",
    "\n",
    "        if len(data_files) > 0:\n",
    "            dataset = pd.concat(map(lambda data_file: pd.read_csv(f\"{data_files_path}/{data_file}\", on_bad_lines=\"warn\"), data_files))\n",
    "        \n",
    "            for column_name in [\"lhs_rows_count\", \"rhs_rows_count\"]:\n",
    "                dataset[column_name] = pd.to_numeric(dataset[column_name], errors=\"coerce\").astype(\"Int64\")\n",
    "    \n",
    "            dataset[\"data_suite_type\"] = dataset.apply(lambda row: \"databio\" if row[\"data_suite\"].startswith(\"databio\") else \"synthetic\", axis=1)\n",
    "            dataset[\"data_suite_name\"] = dataset.apply(lambda row: row[\"data_suite\"] if row[\"data_suite_type\"] == \"databio\" else row[\"data_suite\"][:row[\"data_suite\"].rfind('-')], axis=1)\n",
    "            dataset[\"data_suite_name_short\"] = dataset.apply(lambda row: row[\"data_suite\"].replace(\"databio-\", \"\") if row[\"data_suite_type\"] == \"databio\" else row[\"data_suite_name\"], axis=1)\n",
    "            dataset[\"data_suite_size\"] = dataset.apply(lambda row: DATABIO_SIZES[row[\"data_suite_name\"]] if row[\"data_suite_type\"] == \"databio\" else row[\"data_suite\"][row[\"data_suite\"].rfind('-') + 1:], axis=1)\n",
    "            dataset[\"data_suite_size\"] = pd.to_numeric(dataset[\"data_suite_size\"], errors='coerce').astype(int)        \n",
    "            dataset[\"cluster_size\"] = cluster_size\n",
    "    \n",
    "            datasets.append(dataset)\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2f7efd-c040-49ab-b913-60bc1c33a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_preprocessing_synthetic_benchmark(preprocessors = None):\n",
    "    datasets = load_benchmarks_preprocessing()\n",
    "    Y_AXES = [\"lhs_rows_count\", \"rhs_rows_count\"]\n",
    "\n",
    "    synthetic_data = pd.concat(datasets)\n",
    "    synthetic_data = synthetic_data.query(\"data_suite_type == 'synthetic'\")\n",
    "\n",
    "    if preprocessors is None:\n",
    "        preprocessors = synthetic_data[\"preprocessor\"].unique()\n",
    "        preprocessors = list(preprocessors)\n",
    "        preprocessors.sort()\n",
    "    else:\n",
    "        synthetic_data = preprocessors[synthetic_data[\"preprocessor\"].isin(preprocessors)]\n",
    "\n",
    "    data_sizes = synthetic_data[\"data_suite_size\"].unique()\n",
    "    data_sizes = list(data_sizes)\n",
    "    data_sizes.sort()\n",
    "\n",
    "    data_suites = synthetic_data[\"data_suite_name\"].unique()\n",
    "    data_suites = list(data_suites)\n",
    "    data_suites.sort()\n",
    "\n",
    "    plot_figure, plot_axes = plt.subplots(len(data_suites), len(Y_AXES), figsize=(16, 4 * len(data_suites)), sharex = True, sharey = \"all\")\n",
    "    plt.ticklabel_format(useOffset=False)\n",
    "    shared_ax = None\n",
    "\n",
    "    for (j, values_to_plot) in enumerate(Y_AXES):\n",
    "        plot_data = synthetic_data\n",
    "        \n",
    "        for (i, data_suite_name) in enumerate(data_suites):\n",
    "            subplot_data = plot_data.query(f\"data_suite_name == '{data_suite_name}'\")\n",
    "            \n",
    "            sns.barplot(x=\"data_suite_size\", y=values_to_plot, hue=\"preprocessor\", data=subplot_data, ax=plot_axes[i, j])\n",
    "            plot_axes[i, j].set_yscale('log')\n",
    "            # plot_axes[i, j].set_xticklabels(plot_axes[i, j].get_xticks(), rotation=45)\n",
    "            plot_axes[i, j].legend()\n",
    "            plot_axes[i, j].set_title(f\"Count: {values_to_plot}, dataset: {data_suite_name}.\")\n",
    "            \n",
    "            plot_axes[i, j].xaxis.set_tick_params(labelbottom=True)\n",
    "            plot_axes[i, j].yaxis.set_tick_params(labelbottom=True)\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8ef44d-628b-4521-90af-9f2ce834363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_preprocessing_databio_benchmark(preprocessors = None):\n",
    "    datasets = load_benchmarks_preprocessing()\n",
    "    Y_AXES = [\"lhs_rows_count\", \"rhs_rows_count\"]\n",
    "\n",
    "    synthetic_data = pd.concat(datasets)\n",
    "    synthetic_data = synthetic_data.query(\"data_suite_type == 'databio'\")\n",
    "\n",
    "    if preprocessors is None:\n",
    "        preprocessors = synthetic_data[\"preprocessor\"].unique()\n",
    "        preprocessors = list(preprocessors)\n",
    "        preprocessors.sort()\n",
    "    else:\n",
    "        synthetic_data = preprocessors[synthetic_data[\"preprocessor\"].isin(preprocessors)]\n",
    "\n",
    "    data_sizes = synthetic_data[\"data_suite_size\"].unique()\n",
    "    data_sizes = list(data_sizes)\n",
    "    data_sizes.sort()\n",
    "\n",
    "    data_suites = synthetic_data[\"data_suite_name\"].unique()\n",
    "    data_suites = list(data_suites)\n",
    "    data_suites.sort()\n",
    "\n",
    "    plot_figure, plot_axes = plt.subplots(1, len(Y_AXES), figsize=(16, 4), sharex = True, sharey = \"all\")\n",
    "    plt.ticklabel_format(useOffset=False)\n",
    "    shared_ax = None\n",
    "\n",
    "    for (j, values_to_plot) in enumerate(Y_AXES):\n",
    "        plot_data = synthetic_data\n",
    "        \n",
    "        sns.barplot(x=\"data_suite_name_short\", y=values_to_plot, hue=\"preprocessor\", data=plot_data, ax=plot_axes[j])\n",
    "        plot_axes[j].set_yscale('log')\n",
    "        # plot_axes[i, j].set_xticklabels(plot_axes[i, j].get_xticks(), rotation=45)\n",
    "        plot_axes[j].legend()\n",
    "        plot_axes[j].set_title(f\"Count: {values_to_plot}.\")\n",
    "        \n",
    "        plot_axes[j].xaxis.set_tick_params(labelbottom=True)\n",
    "        plot_axes[j].yaxis.set_tick_params(labelbottom=True)\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
